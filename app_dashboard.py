import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
try:
    from excel_report_generator import generate_excel_report
except ImportError as e:
    # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ì—ëŸ¬ ì¶œë ¥
    st.error(f"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì˜¤ë¥˜ (Excel Report): {e}")
    # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
    import os
    st.write(f"Current Directory: {os.getcwd()}")
    st.write(f"Directory Content: {os.listdir()}")
    generate_excel_report = None
except Exception as e:
    st.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ (Excel Report): {e}")
    generate_excel_report = None
from ai_analyzer import generate_ai_insight

# Page Config
st.set_page_config(page_title="ì‚¬ì „ì˜ì—… ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ“Š ì‚¬ì „ì˜ì—… ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.markdown("---")

@st.cache_data
def load_data(file_source, _file_mtime=None):
    """
    Load data from Excel file with cache busting based on file modification time.
    _file_mtime parameter ensures cache is invalidated when file is updated.
    """
    try:
        # Load 'ê³ ê°ì„¤ë¬¸ì§€DB' sheet
        df = pd.read_excel(file_source, sheet_name='ê³ ê°ì„¤ë¬¸ì§€DB', header=0)
        
        # Filter valid rows (Q1 existence)
        q1_col_name = df.columns[4] 
        df = df[df[q1_col_name].notna()]
        
        return df
    except Exception as e:
        # st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") 
        return None

# Sidebar File Uploader
st.sidebar.header("ğŸ“‚ ë°ì´í„° íŒŒì¼ (Data Source)")
uploaded_file = st.sidebar.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=['xlsx'])

if uploaded_file:
    df = load_data(uploaded_file)
    st.sidebar.success("ì—…ë¡œë“œëœ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
else:
    # Use relative path for Cross-platform / Cloud compatibility
    import os
    # Filename in GitHub is 'DB.xlsx' inside 'ì„¤ë¬¸ì¡°ì‚¬ DB' folder
    base_dir = os.path.dirname(__file__)
    default_path = os.path.join(base_dir, 'ì„¤ë¬¸ì¡°ì‚¬ DB', 'DB.xlsx')
    
    # Try alternate if not found (for local backwards compatibility)
    if not os.path.exists(default_path):
        default_path = os.path.join(base_dir, 'ì„¤ë¬¸ì¡°ì‚¬ DB', 'DEFINE_DB.xlsx')
    
    # Get file modification time for cache busting
    if os.path.exists(default_path):
        file_mtime = os.path.getmtime(default_path)
        df = load_data(default_path, _file_mtime=file_mtime)
    else:
        df = None
        st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if df is not None:
    # --- Columns Mapping ---
    cols = df.columns.tolist()
    
    col_map = {
        cols[1]: 'Date',
        cols[2]: 'Manager',
        cols[3]: 'Spot',
        cols[4]: 'Q1_Awareness',
        cols[5]: 'Q2_Channel',
        cols[6]: 'Q3_Pros',
        cols[7]: 'Q4_Purpose',
        cols[8]: 'Q5_Type',
        cols[9]: 'Q6_Intent',
        cols[10]: 'Q7_Subscription',
        cols[11]: 'Q8_Price',
        cols[12]: 'Addr_City',
        cols[13]: 'Addr_Gu',
        cols[14]: 'Addr_Dong',
        cols[16]: 'Gender',
        cols[17]: 'Grade'
    }
    
    df.rename(columns=col_map, inplace=True)

    # --- Data Cleaning & Mapping ---
    # Ensure Numeric
    for c in ['Q6_Intent', 'Q4_Purpose', 'Q5_Type', 'Q1_Awareness', 'Q2_Channel', 'Q7_Subscription', 'Q8_Price', 'Gender']:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors='coerce')

    # Date
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')

    # Mapping Dictionaries
    q1_map = {1: 'ì˜ ì•Œê³ ìˆë‹¤', 2: 'ë“¤ì–´ë³¸ ì  ìˆë‹¤', 3: 'ì²˜ìŒ ì•Œì•˜ë‹¤'}
    q2_map = {1: 'ì™¸ë¶€í™ë³´', 2: 'ë¶€ë™ì‚°', 3: 'ê°€ì¡±/ì§€ì¸', 4: 'ì˜¥ì™¸ê´‘ê³ ', 5: 'í™ˆí˜ì´ì§€', 6: 'ì˜¨ë¼ì¸ê´‘ê³ ', 7: 'ê¸°ì‚¬'}
    q3_map = {1:'ë¸Œëœë“œ', 2:'ì£¼ê±°ì¾Œì ì„±', 3:'êµí†µí™˜ê²½', 4:'êµìœ¡í™˜ê²½', 5:'íˆ¬ìê°€ì¹˜'}
    q4_map = {1: 'ì‹¤ê±°ì£¼', 2: 'íˆ¬ì', 3: 'ì‹¤ê±°ì£¼+íˆ¬ì'}
    q5_map = {1: '59ã¡', 2: '74ã¡', 3: '75ã¡', 4: '84ã¡'}
    q7_map = {1: 'íŠ¹ë³„ê³µê¸‰', 2: '1ìˆœìœ„', 3: '2ìˆœìœ„', 4: 'ë¬´ì‘ë‹µ'}
    q8_map = {
        1: '11.5~12ì–µ', 2: '12~12.5ì–µ', 3: '12.5~13ì–µ', 4: '13~13.5ì–µ',
        5: '14~14.5ì–µ', 6: '14.5~15ì–µ', 7: '15~15.5ì–µ', 8: '15.5~16ì–µ'
    }
    gender_map = {1: 'ë‚¨ì„±', 2: 'ì—¬ì„±'}

    # Apply Mappings
    if 'Q1_Awareness' in df.columns: df['Q1_Label'] = df['Q1_Awareness'].map(q1_map).fillna('ê¸°íƒ€')
    if 'Q2_Channel' in df.columns: df['Q2_Label'] = df['Q2_Channel'].map(q2_map).fillna('ê¸°íƒ€')
    if 'Q3_Pros' in df.columns: df['Q3_Label'] = df['Q3_Pros'].map(q3_map).fillna('ê¸°íƒ€')
    if 'Q4_Purpose' in df.columns: df['Q4_Label'] = df['Q4_Purpose'].map(q4_map).fillna('ê¸°íƒ€')
    if 'Q5_Type' in df.columns: df['Q5_Label'] = df['Q5_Type'].map(q5_map).fillna('ê¸°íƒ€')
    if 'Q7_Subscription' in df.columns: df['Q7_Label'] = df['Q7_Subscription'].map(q7_map).fillna('ê¸°íƒ€')
    if 'Q8_Price' in df.columns: df['Q8_Label'] = df['Q8_Price'].map(q8_map).fillna('ê¸°íƒ€')
    if 'Gender' in df.columns: df['Gender_Label'] = df['Gender'].map(gender_map).fillna('ë¯¸ê¸°ì¬')

    # --- Sidebar Filters ---
    st.sidebar.header("ğŸ” ìƒì„¸ í•„í„° (Filters)")
    
    # Date Filter
    if 'Date' in df.columns:
        valid_dates = df['Date'].dropna()
        if not valid_dates.empty:
            min_d, max_d = valid_dates.min(), valid_dates.max()
            date_range = st.sidebar.date_input("ğŸ“… ì ‘ìˆ˜ ê¸°ê°„", [min_d, max_d])
            if len(date_range) == 2:
                df = df[(df['Date'] >= pd.Timestamp(date_range[0])) & (df['Date'] <= pd.Timestamp(date_range[1]))]

    # Spot Filter
    if 'Spot' in df.columns:
        spots = df['Spot'].dropna().unique()
        sel_spot = st.sidebar.multiselect("ğŸš© ì˜ì—… ê±°ì ", spots)
        if sel_spot:
            df = df[df['Spot'].isin(sel_spot)]
            
    # Manager Filter
    if 'Manager' in df.columns:
        managers = df['Manager'].dropna().unique()
        sel_mgr = st.sidebar.multiselect("ğŸ‘¤ ë‹´ë‹¹ì/ì¡°", managers)
        if sel_mgr:
            df = df[df['Manager'].isin(sel_mgr)]

    # Preserve a copy of df before Sidebar Region Filters
    filtered_base_df = df.copy()

    # Region Filter (Residense) for Sidebar (Visual only for Main Tab usually)
    if 'Addr_City' in df.columns:
        cities = df['Addr_City'].dropna().unique()
        sel_city = st.sidebar.multiselect("ğŸ  ê±°ì£¼ì§€ (ì‹œ/ë„)", cities)
        if sel_city:
            df = df[df['Addr_City'].isin(sel_city)]
            
    if 'Addr_Gu' in df.columns:
        # Show Gu only available in current df details (dynamic)
        gus = df['Addr_Gu'].dropna().unique()
        sel_gu = st.sidebar.multiselect("ğŸ  ê±°ì£¼ì§€ (ì‹œ/êµ°/êµ¬)", gus)
        if sel_gu:
            df = df[df['Addr_Gu'].isin(sel_gu)]
    
    # --- Excel Report Download Section ---
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“¥ ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸°")
    
    report_type_options = {
        "ğŸ“Š ì „ì²´ ë³´ê³ ì„œ (ë°ì´í„° + ìš”ì•½ + ì°¨íŠ¸)": "ì „ì²´",
        "ğŸ“‹ ë°ì´í„°ë§Œ (ì›ë³¸ + í†µê³„ ìš”ì•½)": "ë°ì´í„°ë§Œ",
    }
    
    selected_report = st.sidebar.selectbox(
        "ë³´ê³ ì„œ ìœ í˜• ì„ íƒ",
        list(report_type_options.keys())
    )
    
    if st.sidebar.button("ğŸ“¥ ì—‘ì…€ ë³´ê³ ì„œ ìƒì„±", type="primary", use_container_width=True):
        with st.sidebar:
            with st.spinner('ë³´ê³ ì„œ ìƒì„± ì¤‘...'):
                try:
                    # í˜„ì¬ í•„í„°ë§ëœ ë°ì´í„°ë¡œ ë³´ê³ ì„œ ìƒì„±
                    report_type = report_type_options[selected_report]
                    
                    if generate_excel_report is None:
                        st.error("ì—‘ì…€ ìƒì„± ëª¨ë“ˆì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìƒë‹¨ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        st.stop()
                        
                    excel_file = generate_excel_report(df, report_type)
                    
                    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (BytesIO ëŒ€ì‹  bytes ë°”ì´íŠ¸ ë¬¸ìì—´ë¡œ ì €ì¥)
                    st.session_state['generated_excel'] = excel_file.getvalue()
                    st.session_state['generated_filename'] = f"PreSales_Report_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx"
                    st.session_state['last_filter_hash'] = hash(str(df.index.tolist())) # ë°ì´í„° ë³€ê²½ ê°ì§€ìš© (ë‹¨ìˆœí™”)
                    
                    st.success("âœ… ìƒì„± ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
                except Exception as e:
                    st.error(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.info("ë°ì´í„°ë§Œ ì˜µì…˜ì„ ì‹œë„í•´ë³´ì„¸ìš”.")

    # ìƒì„±ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
    if 'generated_excel' in st.session_state and st.session_state['generated_excel'] is not None:
        st.sidebar.download_button(
            label="â¬‡ï¸ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=st.session_state['generated_excel'],
            file_name=st.session_state['generated_filename'],
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key=f"dl_{st.session_state['generated_filename']}",
            use_container_width=True
        )

    # --- Metrics ---
    st.header("1. í•µì‹¬ í˜„í™© (Key Metrics)")
    
    total = len(df)
    avg_intent = df['Q6_Intent'].mean() if 'Q6_Intent' in df.columns else 0
    high_intent = len(df[df['Q6_Intent'] >= 6]) if 'Q6_Intent' in df.columns else 0
    
    # Calculate S+A Grade Count if 'Grade' column exists
    sa_count = high_intent
    sa_label = "ê°€ë§ ê³ ê° (Sê¸‰)"
    sa_delta = "ì˜í–¥ 6ì  ì´ìƒ"
    
    if 'Grade' in df.columns:
        # Grade 1(S), 2(A)
        sa_count = len(df[df['Grade'].isin([1, 2])])
        sa_label = "ê°€ë§ ê³ ê° (S/Aê¸‰)"
        sa_delta = "ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨"
        
    conversion = (sa_count / total * 100) if total > 0 else 0
    
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ì‘ë‹µ ìˆ˜", f"{total:,} ê±´", "Total Leads")
    c2.metric("í‰ê·  ë¶„ì–‘ ì˜í–¥ (Q6)", f"{avg_intent:.1f} ì ", "/ 7.0 ë§Œì ")
    c3.metric(sa_label, f"{sa_count:,} ëª…", "S+A ë“±ê¸‰ í•©ê³„")
    c4.metric("ì ì¬ ì „í™˜ìœ¨", f"{conversion:.1f} %", sa_delta)
    
    st.markdown("---")

    # --- Helper: Weekly Period Calculator (Mon-Sun) ---
    def get_weekly_period(date_series):
        """
        Groups dates into weekly buckets (Monday-Sunday).
        Returns a Series of strings: "1ì£¼ì°¨ (12/08~12/14)"
        """
        if date_series.empty:
            return date_series.astype(str)

        # 1. Find the global minimum date to determine Week 1's anchor
        # Ensure we anchor to the Monday of the week containing the min date
        min_date = date_series.min()
        # weekday(): Mon=0, Sun=6. 
        # Subtract current weekday to get Monday.
        start_anchor = min_date - pd.Timedelta(days=min_date.weekday())
        
        # 2. Calculate offset in weeks
        # We need to apply the logic row by row or vectorized
        # Vectorized: (date - anchor).dt.days // 7 + 1
        # Only works if date_series is datetime64
        
        dates = pd.to_datetime(date_series)
        days_diff = (dates - start_anchor).dt.days
        week_nums = (days_diff // 7) + 1
        
        # 3. Calculate Start/End date for each week num
        # Week N Start = Anchor + (N-1)*7
        # Week N End   = Week N Start + 6
        
        results = []
        for d, w in zip(dates, week_nums):
            if pd.isna(d):
                results.append("ë¯¸í™•ì¸")
                continue
                
            w_start = start_anchor + pd.Timedelta(days=(w-1)*7)
            w_end = w_start + pd.Timedelta(days=6)
            
            period_str = f"{w_start.strftime('%m/%d')}~{w_end.strftime('%m/%d')}"
            results.append(f"{w}ì£¼ì°¨ ({period_str})")
            
        return pd.Series(results, index=date_series.index)
    
    # --- Reusable Analysis Function ---
    def draw_analysis_tabs(target_df, key_suffix=""):
        if target_df.empty:
            st.warning("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # Sub-tabs within the analysis view
        t1, t2, t3, t4, t5 = st.tabs(["ğŸ“Š ì„¤ë¬¸ ë¬¸í•­ í†µí•© ë¶„ì„", "ğŸŒ ì¸êµ¬/ì§€ì—­ í†µê³„", "ğŸ† ìƒë‹´ ë“±ê¸‰ ë¶„ì„", "ğŸ“ˆ ì˜ì—… ì„±ê³¼ ë¶„ì„", "ğŸ“… ì£¼ì°¨ë³„ ì¶”ì´"])
        
        # Tab 1: Combined Survey (Q1~Q8)
        with t1:
            st.markdown("#### ğŸ’¡ ì„¤ë¬¸ ì‘ë‹µ ì¢…í•© ë¶„ì„ (Q1~Q8)")
            
            # Row 1: Q1, Q2, Q3
            r1_1, r1_2, r1_3 = st.columns(3)
            with r1_1:
                st.markdown("##### Q1. ì‚¬ì—…ì§€ ì¸ì§€ë„")
                if 'Q1_Label' in target_df.columns:
                     counts = target_df['Q1_Label'].value_counts().reset_index()
                     counts.columns = ['Answer', 'Count']
                     fig = px.pie(counts, values='Count', names='Answer', hole=0.4)
                     fig.update_traces(textposition='inside', textinfo='percent+label')
                     st.plotly_chart(fig, use_container_width=True, key=f"q1_{key_suffix}")
            with r1_2:
                st.markdown("##### Q2. ì •ë³´ ìŠµë“ ê²½ë¡œ")
                if 'Q2_Label' in target_df.columns:
                     counts = target_df['Q2_Label'].value_counts().reset_index()
                     counts.columns = ['Channel', 'Count']
                     fig = px.bar(counts, x='Channel', y='Count', text='Count')
                     st.plotly_chart(fig, use_container_width=True, key=f"q2_{key_suffix}")
            with r1_3:
                st.markdown("##### Q3. ë§Œì¡± ì¥ì ")
                if 'Q3_Label' in target_df.columns:
                    counts = target_df['Q3_Label'].value_counts().reset_index()
                    counts.columns = ['Pros', 'Count']
                    fig = px.bar(counts, x='Pros', y='Count', text='Count')
                    st.plotly_chart(fig, use_container_width=True, key=f"q3_{key_suffix}")

            st.markdown("---")
            
            # Row 2: Q4, Q5, Q6
            r2_1, r2_2, r2_3 = st.columns(3)
            with r2_1:
                st.markdown("##### Q4. êµ¬ë§¤ ëª©ì ")
                if 'Q4_Label' in target_df.columns:
                    counts = target_df['Q4_Label'].value_counts().reset_index()
                    counts.columns = ['Purpose', 'Count']
                    fig = px.bar(counts, x='Purpose', y='Count', color='Purpose', text='Count')
                    st.plotly_chart(fig, use_container_width=True, key=f"q4_{key_suffix}")
            with r2_2:
                st.markdown("##### Q5. ì„ í˜¸ í‰í˜•")
                if 'Q5_Label' in target_df.columns:
                    counts = target_df['Q5_Label'].value_counts().reset_index()
                    counts.columns = ['Type', 'Count']
                    fig = px.pie(counts, values='Count', names='Type', hole=0.4)
                    fig.update_traces(textposition='inside', textinfo='percent+label')
                    st.plotly_chart(fig, use_container_width=True, key=f"q5_{key_suffix}")
            with r2_3:
                st.markdown("##### Q6. ê³„ì•½ ì˜í–¥ (1~7ì )")
                if 'Q6_Intent' in target_df.columns:
                    q6_counts = target_df['Q6_Intent'].value_counts().sort_index().reset_index()
                    q6_counts.columns = ['Score', 'Count']
                    fig = px.bar(q6_counts, x='Score', y='Count', text='Count')
                    fig.update_xaxes(dtick=1)
                    st.plotly_chart(fig, use_container_width=True, key=f"q6_{key_suffix}")

            st.markdown("---")

            # Row 3: Q7, Q8
            r3_1, r3_2, r3_3 = st.columns(3)
            with r3_1:
                st.markdown("##### Q7. ì²­ì•½ ì˜ˆì •")
                if 'Q7_Label' in target_df.columns:
                    counts = target_df['Q7_Label'].value_counts().reset_index()
                    counts.columns = ['Type', 'Count']
                    fig = px.pie(counts, values='Count', names='Type')
                    fig.update_traces(textposition='inside', textinfo='percent+label')
                    st.plotly_chart(fig, use_container_width=True, key=f"q7_{key_suffix}")
            with r3_2:
                st.markdown("##### Q8. í¬ë§ ë¶„ì–‘ê°€")
                if 'Q8_Label' in target_df.columns:
                    order = list(q8_map.values())
                    counts = target_df['Q8_Label'].value_counts().reindex(order).fillna(0).reset_index()
                    counts.columns = ['PriceRange', 'Count']
                    fig = px.bar(counts, x='PriceRange', y='Count', text='Count')
                    st.plotly_chart(fig, use_container_width=True, key=f"q8_{key_suffix}")

        # Tab 2: Demographics
        with t2:
            st.markdown("#### ğŸŒ ì¸êµ¬/ì§€ì—­ í†µê³„")
            
            st.markdown("##### ì¼ë³„ ë° ëˆ„ê³„ ì ‘ìˆ˜ ì¶”ì´")
            if 'Date' in target_df.columns:
                import plotly.graph_objects as go
                from plotly.subplots import make_subplots
                
                daily = target_df.groupby(target_df['Date'].dt.date).size().reset_index(name='Count')
                daily.columns = ['Date', 'Count']
                daily = daily.sort_values('Date')
                
                # Calculate Cumulative Sum
                daily['Cumulative'] = daily['Count'].cumsum()
                
                # Format Date to Korean string
                daily['Date_Str'] = pd.to_datetime(daily['Date']).dt.strftime('%mì›” %dì¼')
                
                # Create figure with secondary y-axis
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                
                # Add Daily Bar
                fig.add_trace(
                    go.Bar(x=daily['Date_Str'], y=daily['Count'], name="ì¼ë³„ ì ‘ìˆ˜", text=daily['Count'], textposition='auto', marker_color='#636EFA', opacity=0.7),
                    secondary_y=False,
                )
                
                # Add Cumulative Line
                fig.add_trace(
                    go.Scatter(x=daily['Date_Str'], y=daily['Cumulative'], name="ëˆ„ê³„ í•©ê³„", mode='lines+markers+text', 
                               text=daily['Cumulative'], textposition='top center', line=dict(color='#EF553B', width=3)),
                    secondary_y=True,
                )
                
                fig.update_layout(
                    title_text="ì¼ë³„ ì ‘ìˆ˜ ë° ëˆ„ê³„ í˜„í™©",
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                )
                
                fig.update_xaxes(title_text="ì ‘ìˆ˜ì¼ì")
                fig.update_yaxes(title_text="ì¼ë³„ ì ‘ìˆ˜ (ê±´)", secondary_y=False)
                fig.update_yaxes(title_text="ëˆ„ê³„ í•©ê³„ (ê±´)", secondary_y=True)
                
                st.plotly_chart(fig, use_container_width=True, key=f"date_{key_suffix}")
            
            st.markdown("#### ê±°ì£¼ ì§€ì—­ (Top 20)")
            if 'Addr_City' in target_df.columns and 'Addr_Gu' in target_df.columns:
                 target_df['Full_Addr'] = target_df['Addr_City'].astype(str) + " " + target_df['Addr_Gu'].astype(str)
                 counts = target_df['Full_Addr'].value_counts().head(20).reset_index()
                 counts.columns = ['Address', 'Count']
                 fig = px.bar(counts, x='Address', y='Count', text='Count')
                 st.plotly_chart(fig, use_container_width=True, key=f"addr_{key_suffix}")

        # Tab 3: Grade
        with t3:
            st.markdown("#### ğŸ† ìƒë‹´ ë“±ê¸‰ (S/A/B/C)")
            if 'Grade' in target_df.columns:
                g_map = {1:'S (ì´ˆê³ ê´€ì‹¬)', 2:'A (ê´€ì‹¬)', 3:'B (ë³´í†µ)', 4:'C (ê´€ë¦¬)'}
                target_df['Grade_Label'] = target_df['Grade'].map(g_map).fillna('ë¯¸ê¸°ì¬')
                
                gc1, gc2 = st.columns([1, 2])
                with gc1:
                    counts = target_df['Grade_Label'].value_counts().reset_index()
                    counts.columns = ['Grade', 'Count']
                    try:
                        counts['Sort'] = counts['Grade'].apply(lambda x: 1 if 'S' in x else (2 if 'A' in x else (3 if 'B' in x else (4 if 'C' in x else 5))))
                        counts = counts.sort_values('Sort')
                    except: pass
                    fig = px.bar(counts, x='Grade', y='Count', color='Grade', text='Count')
                    st.plotly_chart(fig, use_container_width=True, key=f"grd_{key_suffix}")
                with gc2:
                    st.markdown("##### ìƒì„¸ ë¦¬ìŠ¤íŠ¸ (Top 500)")
                    cols = ['Date', 'Manager', 'Addr_Gu', 'Q5_Label', 'Q6_Intent', 'Q4_Label', 'Grade_Label']
                    show_cols = [c for c in cols if c in target_df.columns]
                    
                    # Mapping for Korean Headers
                    header_map = {
                        'Date': 'ì ‘ìˆ˜ì¼ì',
                        'Manager': 'ë‹´ë‹¹ì',
                        'Addr_Gu': 'ê±°ì£¼ì§€ì—­(êµ¬)',
                        'Q5_Label': 'ì„ í˜¸í‰í˜•',
                        'Q6_Intent': 'ì˜í–¥ì ìˆ˜',
                        'Q4_Label': 'êµ¬ë§¤ëª©ì ',
                        'Grade_Label': 'ê³ ê°ë“±ê¸‰'
                    }
                    
                    sorted_list = target_df.sort_values(['Grade', 'Q6_Intent'], ascending=[True, False]).head(500)
                    display_df = sorted_list[show_cols].rename(columns=header_map)
                    st.dataframe(display_df, use_container_width=True)

        # Tab 4: Sales Performance
        with t4:
            st.markdown("#### ğŸ“ˆ ì˜ì—… ì„±ê³¼ ë° íš¨ìœ¨ (Performance)")
            sp_col1, sp_col2 = st.columns(2)
            
            with sp_col1:
                st.markdown("##### ğŸš© ê±°ì ë³„ ìˆ˜ì§‘ ì‹¤ì  (Top 10)")
                if 'Spot' in target_df.columns:
                    spot_counts = target_df['Spot'].value_counts().reset_index().head(10)
                    spot_counts.columns = ['Spot', 'Count']
                    fig = px.bar(spot_counts, x='Spot', y='Count', text='Count', title="ê±°ì ë³„ DB ìˆ˜ì§‘ëŸ‰")
                    st.plotly_chart(fig, use_container_width=True, key=f"perf_sp1_{key_suffix}")
                    
                    if 'Grade' in target_df.columns:
                         st.markdown("##### ğŸ’ ê±°ì ë³„ ìš°ìˆ˜ ë“±ê¸‰(S/A) í˜„í™©")
                         high_grade = target_df[target_df['Grade'].isin([1, 2])].copy()
                         if not high_grade.empty:
                             g_map_perf = {1:'S (ì´ˆê³ ê´€ì‹¬)', 2:'A (ê´€ì‹¬)'}
                             high_grade['Grade_Label'] = high_grade['Grade'].map(g_map_perf)
                             spot_grade = high_grade.groupby(['Spot', 'Grade_Label']).size().reset_index(name='Count')
                             fig3 = px.bar(spot_grade, x='Spot', y='Count', color='Grade_Label', text='Count', title="ê±°ì ë³„ S/A ë“±ê¸‰ í™•ë³´ ìˆ˜", barmode='group')
                             st.plotly_chart(fig3, use_container_width=True, key=f"perf_sp3_{key_suffix}")
                         else:
                             st.info("S/A ë“±ê¸‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            with sp_col2:
                st.markdown("##### ğŸ‘¤ ë‹´ë‹¹ì/ì¡°ë³„ ì‹¤ì  (Top 10)")
                if 'Manager' in target_df.columns:
                    mgr_counts = target_df['Manager'].value_counts().reset_index().head(10)
                    mgr_counts.columns = ['Manager', 'Count']
                    fig = px.bar(mgr_counts, x='Manager', y='Count', text='Count', title="ë‹´ë‹¹ìë³„ ëˆ„ì  ì‹¤ì ")
                    st.plotly_chart(fig, use_container_width=True, key=f"perf_mp1_{key_suffix}")
                
                st.markdown("##### ìƒì„¸ ì„±ê³¼í‘œ")
                if 'Manager' in target_df.columns and 'Q6_Intent' in target_df.columns:
                    mgr_stats = target_df.groupby('Manager').agg(
                        Total_DB=('Manager', 'count'),
                        Avg_Score=('Q6_Intent', 'mean'),
                        S_Count=('Q6_Intent', lambda x: (x>=6).sum())
                    ).reset_index()
                    mgr_stats['S_Ratio'] = (mgr_stats['S_Count'] / mgr_stats['Total_DB'] * 100).round(1)
                    mgr_stats['Avg_Score'] = mgr_stats['Avg_Score'].round(2)
                    mgr_stats = mgr_stats.sort_values('Total_DB', ascending=False)
                    
                    # Mapping for Korean Headers
                    mgr_header_map = {
                        'Manager': 'ë‹´ë‹¹ì/ì¡°',
                        'Total_DB': 'ì´ ì ‘ìˆ˜ëŸ‰',
                        'Avg_Score': 'í‰ê·  ì˜í–¥ì ìˆ˜',
                        'S_Count': 'Sê¸‰(6ì ì´ìƒ)',
                        'S_Ratio': 'Sê¸‰ ë¹„ìœ¨(%)'
                    }
                    st.dataframe(mgr_stats.rename(columns=mgr_header_map), use_container_width=True)

        # Tab 5: Weekly Trend Analysis
        with t5:
            st.markdown("#### ğŸ“… ì£¼ì°¨ë³„ ì„¤ë¬¸ ì‘ë‹µ ì¶”ì´ (Weekly Trend)")
            if 'Date' not in target_df.columns:
                st.warning("ë‚ ì§œ(Date) ë°ì´í„°ê°€ ì—†ì–´ ì£¼ì°¨ë³„ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # 1. Calculate Weeks
                # Make a copy to avoid SettingWithCopy warnings on the original df slice
                analysis_df = target_df.copy()
                analysis_df['Week_Label'] = get_weekly_period(pd.to_datetime(analysis_df['Date']))
                
                # 2. Select Question
                q_options = {
                    'Q1_Label': 'Q1. ì‚¬ì—…ì§€ ì¸ì§€ë„',
                    'Q2_Label': 'Q2. ì •ë³´ ìŠµë“ ê²½ë¡œ',
                    'Q3_Label': 'Q3. ë§Œì¡± ì¥ì ',
                    'Q4_Label': 'Q4. êµ¬ë§¤ ëª©ì ',
                    'Q5_Label': 'Q5. ì„ í˜¸ í‰í˜•',
                    'Q6_Intent': 'Q6. ê³„ì•½ ì˜í–¥ (ì ìˆ˜)',
                    'Q7_Label': 'Q7. ì²­ì•½ ì˜ˆì •',
                    'Q8_Label': 'Q8. í¬ë§ ë¶„ì–‘ê°€'
                }
                
                # Filter out columns that don't exist
                valid_q_options = {k: v for k, v in q_options.items() if k in analysis_df.columns}
                
                if not valid_q_options:
                     st.error("ë¶„ì„í•  ì„¤ë¬¸ ë¬¸í•­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # Visualization Options
                    view_type = st.radio("ê·¸ë˜í”„ ë³´ê¸° ë°©ì‹", ["ê±´ìˆ˜ (Count)", "ë¹„ìœ¨ (Percentage)"], horizontal=True, key=f"wk_view_{key_suffix}")
                    st.markdown("---")

                    # Loop through all questions
                    # We will use a 2-column layout
                    cols = st.columns(2)
                    
                    for idx, (q_key, q_title) in enumerate(valid_q_options.items()):
                        # Determine which column to use (0 or 1)
                        col_idx = idx % 2
                        with cols[col_idx]:
                            st.markdown(f"##### {q_title}")
                            
                            # Special handling for Q6 (Score)
                            if q_key == 'Q6_Intent':
                                # For Q6, we show the Average Score Trend Line
                                weekly_avg = analysis_df.groupby('Week_Label')['Q6_Intent'].mean().reset_index()
                                weekly_avg.columns = ['Week', 'Avg_Score']
                                # Sort naturally if possible, else by Week Label
                                try:
                                    weekly_avg['Week_Num'] = weekly_avg['Week'].apply(lambda x: int(x.split('ì£¼ì°¨')[0]))
                                    weekly_avg = weekly_avg.sort_values('Week_Num')
                                except:
                                    weekly_avg = weekly_avg.sort_values('Week')

                                fig = px.line(weekly_avg, x='Week', y='Avg_Score', markers=True, title="ì£¼ì°¨ë³„ í‰ê·  ê³„ì•½ ì˜í–¥ ì ìˆ˜", text='Avg_Score')
                                fig.update_traces(textposition="bottom center", texttemplate='%{text:.2f}')
                                fig.update_yaxes(range=[0, 8])
                                st.plotly_chart(fig, use_container_width=True, key=f"wk_line_{idx}_{key_suffix}")
                                
                                # Optional: Also show distribution below? 
                                # Might be too crowded. Let's stick to Average Line for Q6 in this grid view
                                # OR show distribution instead if user prefers. 
                                # Let's show the Score Distribution Bar Chart as well.
                                counts = analysis_df.groupby(['Week_Label', 'Q6_Intent']).size().reset_index(name='Count')
                                # Sort logic same as below...
                                try:
                                    counts['Week_Num'] = counts['Week_Label'].apply(lambda x: int(x.split('ì£¼ì°¨')[0]))
                                    counts = counts.sort_values(['Week_Num', 'Q6_Intent'])
                                except:
                                    counts = counts.sort_values(['Week_Label', 'Q6_Intent'])
                                    
                                if "ë¹„ìœ¨" in view_type:
                                     week_totals = counts.groupby('Week_Label')['Count'].transform('sum')
                                     counts['Percent'] = (counts['Count'] / week_totals * 100).round(1)
                                     fig2 = px.bar(counts, x='Week_Label', y='Percent', color='Q6_Intent', text='Percent', title="ì˜í–¥ ì ìˆ˜ ë¶„í¬")
                                     fig2.update_traces(texttemplate='%{text}%', textposition='inside')
                                else:
                                     fig2 = px.bar(counts, x='Week_Label', y='Count', color='Q6_Intent', text='Count', title="ì˜í–¥ ì ìˆ˜ ë¶„í¬")
                                     fig2.update_traces(textposition='inside')
                                st.plotly_chart(fig2, use_container_width=True, key=f"wk_bar_{idx}_{key_suffix}")

                            else:
                                # Categorical Questions
                                counts = analysis_df.groupby(['Week_Label', q_key]).size().reset_index(name='Count')
                                
                                # Sort Lines
                                try:
                                    counts['Week_Num'] = counts['Week_Label'].apply(lambda x: int(x.split('ì£¼ì°¨')[0]))
                                    counts = counts.sort_values(['Week_Num', 'Count'], ascending=[True, False])
                                except:
                                    counts = counts.sort_values('Week_Label')

                                if "ë¹„ìœ¨" in view_type:
                                    week_totals = counts.groupby('Week_Label')['Count'].transform('sum')
                                    counts['Percent'] = (counts['Count'] / week_totals * 100).round(1)
                                    fig = px.bar(counts, x='Week_Label', y='Percent', color=q_key, text='Percent')
                                    fig.update_traces(texttemplate='%{text}%', textposition='inside')
                                else:
                                    fig = px.bar(counts, x='Week_Label', y='Count', color=q_key, text='Count')
                                    fig.update_traces(textposition='inside')
                                    
                                st.plotly_chart(fig, use_container_width=True, key=f"wk_chart_{idx}_{key_suffix}")
                            
                            st.markdown("---")


    # --- Top Tabs ---
    main_tabs = st.tabs(["ğŸ“Š ì „ì²´ ë¶„ì„", "ğŸŸ¢ ì„œëŒ€ë¬¸êµ¬", "ğŸ”µ ë§ˆí¬êµ¬", "ğŸŸ£ ì€í‰êµ¬", "ğŸ“ˆ ê³ ê¸‰ ë¶„ì„", "ğŸ¤– AI ë¶„ì„"])
    
    # 1. Main Analysis
    with main_tabs[0]:
        st.subheader("ğŸ“Š ì „ì²´ ë°ì´í„° ë¶„ì„")
        # Apply Sidebar Region Filter ONLY here
        view_df = filtered_base_df.copy()
        if sel_city:
            view_df = view_df[view_df['Addr_City'].isin(sel_city)]
        if sel_gu:
            view_df = view_df[view_df['Addr_Gu'].isin(sel_gu)]
            
        draw_analysis_tabs(view_df, "main")

    # 2. Seodaemun
    with main_tabs[1]:
        st.header("ğŸŸ¢ ì„œëŒ€ë¬¸êµ¬ ê±°ì£¼ ê³ ê° ë¶„ì„")
        target = filtered_base_df[filtered_base_df['Addr_Gu'] == 'ì„œëŒ€ë¬¸êµ¬']
        st.info(f"ì„ íƒ ê¸°ê°„ ë‚´ ì„œëŒ€ë¬¸êµ¬ ê±°ì£¼ ì‘ë‹µ ìˆ˜: {len(target):,} ëª…")
        draw_analysis_tabs(target, "seo")

    # 3. Mapo
    with main_tabs[2]:
        st.header("ğŸ”µ ë§ˆí¬êµ¬ ê±°ì£¼ ê³ ê° ë¶„ì„")
        target = filtered_base_df[filtered_base_df['Addr_Gu'] == 'ë§ˆí¬êµ¬']
        st.info(f"ì„ íƒ ê¸°ê°„ ë‚´ ë§ˆí¬êµ¬ ê±°ì£¼ ì‘ë‹µ ìˆ˜: {len(target):,} ëª…")
        draw_analysis_tabs(target, "mapo")

    # 4. Eunpyeong
    with main_tabs[3]:
        st.header("ğŸŸ£ ì€í‰êµ¬ ê±°ì£¼ ê³ ê° ë¶„ì„")
        target = filtered_base_df[filtered_base_df['Addr_Gu'] == 'ì€í‰êµ¬']
        st.info(f"ì„ íƒ ê¸°ê°„ ë‚´ ì€í‰êµ¬ ê±°ì£¼ ì‘ë‹µ ìˆ˜: {len(target):,} ëª…")
        draw_analysis_tabs(target, "eun")

    # 5. Advanced Analytics Dashboard (Moved to Tab)
    with main_tabs[4]:
        st.header("ğŸ“ˆ ê³ ê¸‰ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
        st.caption("ë¦¬ë“œ ìŠ¤ì½”ì–´ë§, RFIE ì„¸ê·¸ë¨¼íŠ¸, ê²½ê³  ì‹œìŠ¤í…œì„ í†µí•œ ì‹¬ì¸µ ë¶„ì„")
    
    # Import advanced analytics
    try:
        from advanced_analytics import (
            apply_lead_scoring,
            get_lead_score_summary,
            calculate_rfie_scores,
            get_rfie_summary,
            get_segment_summary,
            generate_alerts
        )
        
        # Apply lead scoring
        df_scored = apply_lead_scoring(df)
        lead_summary = get_lead_score_summary(df_scored)
        
        # Apply RFIE
        df_rfie = calculate_rfie_scores(df)
        rfie_summary = get_rfie_summary(df_rfie)
        
        # Create tabs for advanced analytics
        adv_tabs = st.tabs(["ğŸ¯ ë¦¬ë“œ ìŠ¤ì½”ì–´ë§", "ğŸ“Š RFIE ì„¸ê·¸ë¨¼íŠ¸", "âš ï¸ ê²½ê³ /ì•Œë¦¼"])
        
        # Tab 1: Lead Scoring
        with adv_tabs[0]:
            # ì„¤ëª… ë°•ìŠ¤ ì¶”ê°€
            with st.expander("â„¹ï¸ ë¦¬ë“œ ìŠ¤ì½”ì–´ë§ì´ë€?", expanded=False):
                st.markdown("""
                **ë¦¬ë“œ ìŠ¤ì½”ì–´ë§**ì€ ê° ê³ ê°ì˜ **ê³„ì•½ ê°€ëŠ¥ì„±ì„ 0~100ì ìœ¼ë¡œ ìˆ˜ì¹˜í™”**í•œ ê²ƒì…ë‹ˆë‹¤.
                
                **ğŸ“Š ì ìˆ˜ ì‚°ì • ê¸°ì¤€:**
                | í•­ëª© | ê¸°ì¤€ | ìµœëŒ€ ì ìˆ˜ |
                |------|------|----------|
                | ê³„ì•½ ì˜í–¥ (Q6) | 7ì  ì´ìƒ â†’ 30ì , 5~6ì  â†’ 20ì  | 30ì  |
                | ì²­ì•½ ìê²© (Q7) | 1ìˆœìœ„/2ìˆœìœ„/íŠ¹ë³„ê³µê¸‰ ë³´ìœ  ì‹œ | 25ì  |
                | í¬ë§ ë¶„ì–‘ê°€ (Q8) | ë¶„ì–‘ê°€ ë²”ìœ„ ë‚´ | 20ì  |
                | êµ¬ë§¤ ëª©ì  (Q4) | ì‹¤ê±°ì£¼ â†’ 15ì , íˆ¬ì â†’ 10ì  | 15ì  |
                | ìœ ì… ê²½ë¡œ (Q2) | ì§€ì¸ ì¶”ì²œ â†’ 15ì , ì˜¨ë¼ì¸ â†’ 8ì  | 10ì  |
                
                **ğŸ·ï¸ ë“±ê¸‰ ë¶„ë¥˜:**
                - ğŸ”´ **Aê¸‰ (80ì â†‘)**: ì¦‰ì‹œ ê³„ì•½ ê°€ëŠ¥! ë°”ë¡œ ì „í™”í•˜ì„¸ìš”
                - ğŸŸ  **Bê¸‰ (60~79ì )**: ê´€ì‹¬ ë†’ìŒ, 48ì‹œê°„ ë‚´ ì—°ë½
                - ğŸŸ¡ **Cê¸‰ (40~59ì )**: ìœ¡ì„± í•„ìš”, ì£¼ê°„ ë‰´ìŠ¤ë ˆí„°
                - âšª **Dê¸‰ (40ì â†“)**: ì¥ê¸° ê´€ë¦¬, ì›”ê°„ ë¦¬ë§ˆì¸ë“œ
                """)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ë¦¬ë“œ ë“±ê¸‰ ë¶„í¬")
                st.caption("ê³ ê°ë“¤ì´ ì–´ë–¤ ë“±ê¸‰ì— ë¶„í¬í•˜ëŠ”ì§€ í•œëˆˆì— íŒŒì•…")
                grade_counts = df_scored['Lead_Grade'].value_counts()
                fig_lead = px.pie(
                    values=grade_counts.values,
                    names=grade_counts.index,
                    color_discrete_sequence=['#FF6B6B', '#FFA94D', '#FFD93D', '#C0C0C0'],
                    hole=0.4
                )
                fig_lead.update_layout(height=350)
                st.plotly_chart(fig_lead, use_container_width=True)
            
            with col2:
                st.subheader("ë¦¬ë“œ ìŠ¤ì½”ì–´ í†µê³„")
                st.caption("ë“±ê¸‰ë³„ ê³ ê° ìˆ˜ì™€ ë¹„ìœ¨")
                st.metric("í‰ê·  ìŠ¤ì½”ì–´", f"{lead_summary['í‰ê· _ìŠ¤ì½”ì–´']}ì ", help="ì „ì²´ ê³ ê°ì˜ í‰ê·  ë¦¬ë“œ ìŠ¤ì½”ì–´")
                st.metric("Aê¸‰ ê³ ê°", f"{lead_summary['Aê¸‰_ìˆ˜']}ëª… ({lead_summary.get('Aê¸‰_ë¹„ìœ¨', '0%')})", help="ì¦‰ì‹œ ê³„ì•½ ê°€ëŠ¥í•œ í•µì‹¬ ê³ ê°")
                st.metric("Bê¸‰ ê³ ê°", f"{lead_summary['Bê¸‰_ìˆ˜']}ëª… ({lead_summary.get('Bê¸‰_ë¹„ìœ¨', '0%')})", help="ê´€ì‹¬ë„ ë†’ì€ ì ì¬ ê³ ê°")
                st.metric("Cê¸‰ ê³ ê°", f"{lead_summary['Cê¸‰_ìˆ˜']}ëª… ({lead_summary.get('Cê¸‰_ë¹„ìœ¨', '0%')})", help="ìœ¡ì„±ì´ í•„ìš”í•œ ê³ ê°")
            
            # Segment details
            st.subheader("ì„¸ê·¸ë¨¼íŠ¸ë³„ íŠ¹ì„±")
            st.caption("ê° ë“±ê¸‰ ê³ ê°ë“¤ì˜ ì£¼ìš” íŠ¹ì„± - í´ë¦­í•˜ë©´ ìƒì„¸ ì •ë³´ í™•ì¸")
            segment_details = get_segment_summary(df_scored)
            for grade, info in segment_details.items():
                with st.expander(f"{grade} - {info['ê³ ê°_ìˆ˜']}ëª… ({info['ë¹„ìœ¨']})"):
                    cols = st.columns(3)
                    cols[0].write(f"**ì„ í˜¸ í‰í˜•:** {info.get('ì„ í˜¸_í‰í˜•', 'N/A')}")
                    cols[1].write(f"**ì£¼ìš” ìœ ì…:** {info.get('ì£¼ìš”_ìœ ì…ê²½ë¡œ', 'N/A')}")
                    cols[2].write(f"**ì£¼ìš” ëª©ì :** {info.get('ì£¼ìš”_ëª©ì ', 'N/A')}")
        
        # Tab 2: RFIE Segment
        with adv_tabs[1]:
            # ì„¤ëª… ë°•ìŠ¤ ì¶”ê°€
            with st.expander("â„¹ï¸ RFIE ë¶„ì„ì´ë€?", expanded=False):
                st.markdown("""
                **RFIE ë¶„ì„**ì€ ê³ ê°ì„ **4ê°€ì§€ ê´€ì **ì—ì„œ í‰ê°€í•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„ë¥˜í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
                
                **ğŸ“Š RFIE êµ¬ì„± ìš”ì†Œ:**
                | ì§€í‘œ | ì˜ë¯¸ | ì ìˆ˜ ê¸°ì¤€ |
                |------|------|----------|
                | **R** (Recency) | ìµœê·¼ ì‘ë‹µì¼ | ìµœê·¼ì¼ìˆ˜ë¡ ë†’ìŒ (1~5ì ) |
                | **F** (Frequency) | ì ‘ì´‰ ë¹ˆë„ | í˜„ì¬ 1íšŒ ê³ ì • (3ì ) |
                | **I** (Intent) | ê³„ì•½ ì˜í–¥ | ì˜í–¥ ì ìˆ˜ ê¸°ë°˜ (1~5ì ) |
                | **E** (Eligibility) | ì²­ì•½ ìê²© | ë³´ìœ  ì‹œ +2ì  |
                
                **ğŸ·ï¸ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜ (ì´ì  ê¸°ì¤€):**
                - ğŸ† **Champion (15ì â†‘)**: VIP ê³ ê°! ì¦‰ì‹œ ê³„ì•½ ê°€ëŠ¥
                - â­ **Loyal (12~14ì )**: ì¶©ì„±ë„ ë†’ìŒ, ì¶”ê°€ ì„¤ë“ í•„ìš”
                - ğŸŒ± **Promising (8~11ì )**: ì„±ì¥ ê°€ëŠ¥ì„± ìˆìŒ, ìœ¡ì„± ëŒ€ìƒ
                - ğŸ’¤ **At Risk (5~7ì )**: ê´€ì‹¬ ì €í•˜, ì¬í™œì„±í™” í•„ìš”
                - âŒ **Lost (5ì â†“)**: ì´íƒˆ ìœ„í—˜, ì¥ê¸° ê´€ë¦¬
                
                **ğŸ’¡ í™œìš© íŒ:** Championê³¼ Loyalì— ë§ˆì¼€íŒ… ìì›ì„ ì§‘ì¤‘í•˜ê³ , At RiskëŠ” ë¦¬ë§ˆì¸ë“œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì„¸ìš”!
                """)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("RFIE ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬")
                st.caption("ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ ê³ ê° ìˆ˜")
                segment_counts = df_rfie['RFIE_Segment'].value_counts()
                fig_rfie = px.bar(
                    x=segment_counts.index,
                    y=segment_counts.values,
                    color=segment_counts.index,
                    color_discrete_sequence=['#FFD700', '#FFA500', '#32CD32', '#87CEEB', '#DC143C']
                )
                fig_rfie.update_layout(height=350, showlegend=False, xaxis_title="ì„¸ê·¸ë¨¼íŠ¸", yaxis_title="ê³ ê° ìˆ˜")
                st.plotly_chart(fig_rfie, use_container_width=True)
            
            with col2:
                st.subheader("RFIE ì ìˆ˜ ë¶„í¬")
                st.caption("ê³ ê°ë“¤ì˜ RFIE ì ìˆ˜ê°€ ì–´ë–»ê²Œ ë¶„í¬í•˜ëŠ”ì§€")
                fig_hist = px.histogram(df_rfie, x='RFIE_Score', nbins=15, color_discrete_sequence=['#6C5CE7'])
                fig_hist.update_layout(height=350, xaxis_title="RFIE ì ìˆ˜", yaxis_title="ê³ ê° ìˆ˜")
                st.plotly_chart(fig_hist, use_container_width=True)
            
            st.subheader("RFIE í†µê³„")
            st.caption("ì„¸ê·¸ë¨¼íŠ¸ë³„ ê³ ê° ìˆ˜ ìš”ì•½")
            rfie_cols = st.columns(5)
            rfie_cols[0].metric("ğŸ† Champion", f"{rfie_summary['Champion_ìˆ˜']}ëª…", help="ìµœìš°ìˆ˜ ê³ ê°, ë°”ë¡œ ê³„ì•½ ê°€ëŠ¥")
            rfie_cols[1].metric("â­ Loyal", f"{rfie_summary['Loyal_ìˆ˜']}ëª…", help="ì¶©ì„±ë„ ë†’ì€ ê³ ê°")
            rfie_cols[2].metric("ğŸŒ± Promising", f"{rfie_summary['Promising_ìˆ˜']}ëª…", help="ì„±ì¥ ê°€ëŠ¥ì„± ìˆëŠ” ê³ ê°")
            rfie_cols[3].metric("ğŸ’¤ At Risk", f"{rfie_summary['AtRisk_ìˆ˜']}ëª…", help="ê´€ì‹¬ ì €í•˜ëœ ê³ ê°, ë¦¬ë§ˆì¸ë“œ í•„ìš”")
            rfie_cols[4].metric("âŒ Lost", f"{rfie_summary['Lost_ìˆ˜']}ëª…", help="ì´íƒˆ ìœ„í—˜ ê³ ê°")
        
        # Tab 3: Alerts
        with adv_tabs[2]:
            # ì„¤ëª… ë°•ìŠ¤ ì¶”ê°€
            with st.expander("â„¹ï¸ ê²½ê³  ì‹œìŠ¤í…œì´ë€?", expanded=False):
                st.markdown("""
                **ê²½ê³  ì‹œìŠ¤í…œ**ì€ ë°ì´í„°ì—ì„œ **ì£¼ì˜ê°€ í•„ìš”í•œ íŒ¨í„´ì„ ìë™ìœ¼ë¡œ ê°ì§€**í•©ë‹ˆë‹¤.
                
                **ğŸ” ìë™ ê°ì§€ í•­ëª©:**
                - ğŸ“‰ í‰ê·  ì˜í–¥ ì ìˆ˜ê°€ 5.0ì  ì´í•˜ë¡œ ë‚®ì„ ë•Œ
                - ğŸ“‹ ì²­ì•½ ìê²© ë³´ìœ ìœ¨ì´ 30% ë¯¸ë§Œì¼ ë•Œ
                - ğŸ  íŠ¹ì • í‰í˜•ì— 50% ì´ìƒ ì ë¦´ ë•Œ (ì¬ê³  ë¦¬ìŠ¤í¬)
                
                **ğŸ’¡ í™œìš© ë°©ë²•:**
                - ê²½ê³ ê°€ ëœ¨ë©´ í•´ë‹¹ í•­ëª©ì„ ì¦‰ì‹œ ì ê²€í•˜ì„¸ìš”
                - ê¶Œì¥ ì•¡ì…˜ì„ ì°¸ê³ í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµì„ ì¡°ì •í•˜ì„¸ìš”
                """)
            
            st.subheader("âš ï¸ ì£¼ì˜ ì‚¬í•­ ë° ê²½ê³ ")
            st.caption("ë°ì´í„°ì—ì„œ ìë™ìœ¼ë¡œ ê°ì§€ëœ ì£¼ì˜ ì‚¬í•­")
            alerts = generate_alerts(df)
            
            if alerts:
                for alert in alerts:
                    st.warning(alert)
            else:
                st.success("âœ… í˜„ì¬ íŠ¹ë³„í•œ ê²½ê³  ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì§€í‘œê°€ ì •ìƒ ë²”ìœ„ì…ë‹ˆë‹¤.")
            
            st.subheader("ğŸ“‹ ê¶Œì¥ ì•¡ì…˜")
            st.caption("í˜„ì¬ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí•˜ëŠ” ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜")
            st.info("ğŸ’¡ Aê¸‰ ê³ ê°ì—ê²Œ ì¦‰ì‹œ 1:1 ì „í™” ìƒë‹´ì„ ì§„í–‰í•˜ì„¸ìš”.")
            if lead_summary['Aê¸‰_ìˆ˜'] > 0:
                st.info(f"ğŸ’¡ í˜„ì¬ Aê¸‰ ê³ ê° {lead_summary['Aê¸‰_ìˆ˜']}ëª…ì—ê²Œ VIP í”„ë¡œëª¨ì…˜ì„ ì•ˆë‚´í•˜ì„¸ìš”.")
            if rfie_summary['AtRisk_ìˆ˜'] > 0:
                st.info(f"ğŸ’¡ At Risk ê³ ê° {rfie_summary['AtRisk_ìˆ˜']}ëª…ì—ê²Œ ë¦¬ë§ˆì¸ë“œ ë©”ì‹œì§€ë¥¼ ë°œì†¡í•˜ì„¸ìš”.")
    
    except Exception as e:
        st.error(f"ê³ ê¸‰ ë¶„ì„ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {str(e)}")

    # 6. AI Analyst (Moved to Tab)
    with main_tabs[5]:
        st.header("ğŸ¤– AI ë°ì´í„° ì‹¬ì¸µ ë¶„ì„")
        st.caption("Google Gemini AIê°€ í˜„ì¬ í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.")
    
    # Initialize session state for AI result
    if 'ai_result' not in st.session_state:
        st.session_state['ai_result'] = None

    col_ai1, col_ai2 = st.columns([1, 4])
    
    with col_ai1:
        if st.button("ğŸš€ AI ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
            with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 10~20ì´ˆ ì†Œìš”)"):
                st.session_state['ai_result'] = generate_ai_insight(df)
    
    with col_ai2:
        if st.session_state['ai_result'] and "âš ï¸" not in st.session_state['ai_result'] and "âŒ" not in st.session_state['ai_result']:
            try:
                from pdf_report_generator import generate_pdf_report
                
                # PDF ìƒì„±ì— í•„ìš”í•œ ë°ì´í„° ì¤€ë¹„
                pdf_data = generate_pdf_report(
                    df, 
                    ai_insight=st.session_state['ai_result'],
                    lead_summary=lead_summary,
                    rfie_summary=rfie_summary
                )
                
                st.download_button(
                    label="ğŸ“¥ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (PDF)",
                    data=pdf_data,
                    file_name=f"ì‚¬ì „ì˜ì—…_ì¢…í•©ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                    mime="application/pdf",
                    use_container_width=True
                )
            except Exception as e:
                st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if st.session_state['ai_result']:
        if "âš ï¸" in st.session_state['ai_result'] or "âŒ" in st.session_state['ai_result']:
            st.error(st.session_state['ai_result'])
        else:
            st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸")
            st.markdown(st.session_state['ai_result'])
            st.markdown("---")
            st.caption("â€» ì´ ë¶„ì„ ê²°ê³¼ëŠ” AIì— ì˜í•´ ìƒì„±ë˜ì—ˆìœ¼ë©°, ì‹¤ì œ ì „ëµ ìˆ˜ë¦½ ì‹œ ì°¸ê³ ìš©ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.")

else:
    st.error("ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
